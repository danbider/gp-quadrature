{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 5000\n",
    "# # sample y from a Gaussian Process\n",
    "# true_length_scale = 0.1\n",
    "# true_variance = 2\n",
    "# true_noise_variance = 0.1\n",
    "# def sample_gp(x, mean_func, cov_func, num_samples=1, length_scale=1.0, variance=1.0):\n",
    "#     \"\"\"\n",
    "#     Sample from a Gaussian Process.\n",
    "    \n",
    "#     Parameters:\n",
    "#     x : np.ndarray\n",
    "#         Input points where the GP is evaluated.\n",
    "#     mean_func : callable\n",
    "#         Mean function of the GP.\n",
    "#     cov_func : callable\n",
    "#         Covariance function of the GP.\n",
    "#     num_samples : int\n",
    "#         Number of samples to draw from the GP.\n",
    "    \n",
    "#     Returns:\n",
    "#     np.ndarray\n",
    "#         Samples from the GP at the input points x.\n",
    "#     \"\"\"\n",
    "#     # Compute the mean and covariance matrix\n",
    "#     mean = mean_func(x)\n",
    "#     cov = cov_func(x, x, length_scale=true_length_scale, variance=true_variance)\n",
    "    \n",
    "#     # Draw samples from the multivariate normal distribution\n",
    "#     samples = torch.tensor(np.random.multivariate_normal(mean, cov, num_samples))\n",
    "    \n",
    "#     return samples.T  # Transpose to get samples along columns\n",
    "# # Example mean and covariance functions\n",
    "# def mean_func(x):\n",
    "#     return torch.zeros_like(x)\n",
    "# def cov_func(x1, x2,length_scale=1.0,variance=1.0):\n",
    "#     return torch.tensor(variance*np.exp((-0.5 * np.subtract.outer(x1, x2)**2)/length_scale**2))\n",
    "# # Generate input points\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # x = torch.linspace(-1, 1, n, dtype=torch.float64)\n",
    "# # Sample from the GP\n",
    "# # y = sample_gp(x, mean_func, cov_func, num_samples=1,length_scale=true_length_scale, variance=true_variance)\n",
    "# # y = y.to(dtype=torch.float64).flatten()+ true_noise_variance * torch.randn(n, dtype=torch.float64)\n",
    "# # Plot the samples\n",
    "# # plt.figure(figsize=(10, 5))\n",
    "# # plt.plot(x, y)\n",
    "# # plt.title(\"Samples from a Gaussian Process, parameters: length_scale=%.2f, variance=%.2f, noise_variance=%.2f\" % (true_length_scale, true_variance, true_noise_variance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "eps = EPSILON\n",
    "trace_samples =10\n",
    "sigmasq = torch.tensor(0.1, dtype=torch.float64)  # noise variance\n",
    "init_kernel\n",
    "x_new = x \n",
    "num_iters = 1\n",
    "# def efgp1d_gradient(x, y, sigmasq, kernel,eps,trace_samples):\n",
    "# x = x.to(dtype=torch.float64).flatten()   # shape: (N,)\n",
    "y = y.to(dtype=torch.float64).flatten()     # shape: (N,)\n",
    "x0, x1 = torch.min(x), torch.max(x)\n",
    "# opts = {'get_var': True, 'get_log_marginal_likelihood': True}\n",
    "L = x1 - x0\n",
    "N = x.shape[0]\n",
    "# eps = EPSILON\n",
    "# eps = 1e-20\n",
    "\n",
    "# Get Fourier frequencies and weights.\n",
    "xis, h, mtot = get_xis(kernel, eps, L)  # Expect len(xis)=M (e.g., M=97)\n",
    "# Compute weights: ws = sqrt(S(xis)*h)\n",
    "ws = torch.sqrt(kernel.spectral_density(xis) * h)  # ws: (M,)   # will change to h^d \n",
    "D = torch.diag(ws).to(dtype=torch.complex128)         # D: (M, M)\n",
    "\n",
    "# Form design features F (size: (N, M)).\n",
    "#TODO : use UFFTConv1d instead of this\n",
    "F = torch.exp(1j * 2 * math.pi * torch.outer(x, xis)).to(dtype=torch.complex128)\n",
    "#TODO higher dim \n",
    "# F = torch.exp(1j * 2 * torch.pi * (x@xis.t()).to(dtype=torch.complex128))\n",
    "\n",
    "v, j_indices = compute_convolution_vector_vectorized(m=int((mtot - 1) / 2), x=x, h=h)\n",
    "Afun = lambda beta: D @ FFTConv1d(v, D @ beta)() + sigmasq * beta\n",
    "\n",
    "\n",
    "# A = D @ (torch.conj(F).T @ F) @ D  # A: (M, M)\n",
    "\n",
    "# -------------------\n",
    "# Compute term 2: easy way\n",
    "# rhs = D @ torch.conj(F).T @ y.to(dtype=torch.complex128)  # rhs: (M,)\n",
    "\n",
    "\n",
    "#via NUFFT \n",
    "xcen = (x1+x0)/2\n",
    "tphx = 2*math.pi*h*(x - xcen)\n",
    "# tphxtrgs = 2*math.pi*h*(x - xcen)\n",
    "\n",
    "\n",
    "nuffttol = EPSILON/20\n",
    "isign = -1\n",
    "fadjbeta = lambda beta: torch.tensor(finufft.nufft1d1(x=tphx.numpy(), c=beta.to(torch.complex128).numpy(),isign= isign, eps= nuffttol, n_modes=mtot))\n",
    "rhs = fadjbeta(y)\n",
    "# rhs = finufft.nufft1d1(x=tphx.numpy(), c=y.to(torch.complex128).numpy(),isign= isign, eps= nuffttol, n_modes=mtot)\n",
    "rhs = ws * rhs;       \n",
    "\n",
    "## want F^* alpha\n",
    "\n",
    "# cg_object = ConjugateGradients(\n",
    "#     A_apply_function=A + sigmasq * torch.eye(mtot, dtype=A.dtype),\n",
    "#     b=rhs,\n",
    "#     x0=torch.zeros_like(rhs),\n",
    "#     early_stopping=opts.get('early_stopping', False)\n",
    "# )\n",
    "cg_object = ConjugateGradients(\n",
    "    A_apply_function=Afun,\n",
    "    b=rhs,\n",
    "    x0=torch.zeros_like(rhs),\n",
    "    early_stopping=False\n",
    "    # early_stopping=opts.get('early_stopping', False)\n",
    ")\n",
    "beta = cg_object.solve()  # beta: (M,)\n",
    "alpha = 1/sigmasq * (y - F @ D @ beta)  # alpha: (N,)\n",
    "\n",
    "# -------------------\n",
    "Dprime = h * kernel.spectral_grad(xis)  # shape: (M, n_params)\n",
    "# This yields the derivative of the diagonal of D^2, since D^2 = diag(S(xis)*h).\n",
    "\n",
    "# --- Embed each column of Dprime as a diagonal matrix.\n",
    "# Dprime is (M, n_params); we want each column (length M) as an (M,M) diagonal.\n",
    "# Transpose so each row corresponds to one hyperparameter:\n",
    "Dprime_t = Dprime.transpose(0, 1)   # shape: (n_params, M)\n",
    "# Embed each row into a diagonal matrix -> (n_params, M, M)\n",
    "D_diag_temp = torch.diag_embed(Dprime_t).to(dtype=torch.complex128)  # shape: (n_params, M, M)\n",
    "\n",
    "# -------------------\n",
    "# Compute khat_prime for the kernel hyperparameters:\n",
    "# For each hyperparameter i, we want:\n",
    "#     khat_prime_i = F * diag(Dprime_i) * F^*\n",
    "# Expand F and its conjugate-transpose to include a batch dimension.\n",
    "# TODO : use nufft \n",
    "N_val, M_val = F.shape  # M_val should equal M.\n",
    "F_expand = F.unsqueeze(0).expand(D_diag_temp.shape[0], N_val, M_val)  # shape: (n_params, N, M)\n",
    "F_adjoint = F.conj().transpose(-2, -1)  # shape: (M, N)\n",
    "F_adjoint_expand = F_adjoint.unsqueeze(0).expand(D_diag_temp.shape[0], M_val, N_val)  # shape: (n_params, M, N)\n",
    "# Batched multiplication:\n",
    "\n",
    "## FD' F^* \n",
    "khat_prime_kernel = torch.bmm(torch.bmm(F_expand, D_diag_temp), F_adjoint_expand)  # shape: (n_params, N, N)\n",
    "\n",
    "# Append the noise derivative (for noise, d/dσ² (K+σ²I) = I) as an extra hyperparameter.\n",
    "noise_derivative = torch.eye(N, dtype=khat_prime_kernel.dtype).unsqueeze(0)  # shape: (1, N, N)\n",
    "khat_prime_kernel_full = torch.cat([khat_prime_kernel, noise_derivative], dim=0)  # shape: (n_params+1, N, N)\n",
    "# Optionally, permute so that the hyperparameter dimension is last:\n",
    "khat_prime = khat_prime_kernel_full.permute(1, 2, 0)  # shape: (N, N, n_params+1)\n",
    "\n",
    "# -------------------\n",
    "# Compute term 2 (quadratic term) for each hyperparameter:\n",
    "# For hyperparameter i, term2_i = α^* (dK/dθ_i) α.\n",
    "term2 = torch.zeros(khat_prime.shape[2], dtype=torch.complex128)\n",
    "for i in range(khat_prime.shape[2]-1):\n",
    "    ## alpha^* F D' F^* alpha\n",
    "    fadjalpha = fadjbeta(alpha)\n",
    "    term2[i] = fadjalpha.conj()@ (Dprime[:,i]*fadjalpha)\n",
    "# term2[i] = torch.matmul(alpha.conj().unsqueeze(0),\n",
    "#                         torch.matmul(khat_prime[:, :, i], alpha.unsqueeze(1))).squeeze()\n",
    "term2[-1] = alpha.conj() @ alpha  # noise term\n",
    "# -------------------\n",
    "# Compute term 1 (trace term) via Monte Carlo.\n",
    "# trace_samples = 10\n",
    "# try with rademachers instead..\n",
    "\n",
    "\n",
    "# Z = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "#         loc=torch.zeros_like(x),\n",
    "#         covariance_matrix=torch.eye(N, dtype=torch.float64)\n",
    "#     ).sample([trace_samples])  # shape: (trace_samples, N)\n",
    "# sample Z iid rademacher variables shape (trace_samples, N)\n",
    "Z = torch.randint(0, 2, (trace_samples, N), dtype=torch.float64) * 2 - 1\n",
    "\n",
    "term1 = torch.zeros(khat_prime.shape[2], dtype=torch.complex128)\n",
    "for i in range(khat_prime.shape[2]):  # for each hyperparameter derivative\n",
    "    sum_term1 = 0.0 + 0.0j\n",
    "#TODO: fix the apply function here \n",
    "    for j in range(trace_samples):\n",
    "        z_sample = Z[j, :].to(dtype=torch.complex128)  # shape: (N,)\n",
    "        temp_rhs = khat_prime[:, :, i] @ z_sample.unsqueeze(1)  # shape: (N, 1)\n",
    "        rhs_sample = D @ torch.conj(F).T @ temp_rhs  # shape: (M, 1)\n",
    "        cg_object = ConjugateGradients(\n",
    "            A_apply_function=Afun,\n",
    "            b=rhs_sample.squeeze(),  # shape: (M,)\n",
    "            x0=torch.zeros_like(rhs_sample.squeeze()),\n",
    "            early_stopping=False\n",
    "        )\n",
    "        beta_sample = cg_object.solve()  # shape: (M,)\n",
    "        # alpha_sample = 1/sigmasq * (y - F @ D @ beta_sample)  # shape: (N,)\n",
    "        alpha_sample = 1/sigmasq * (temp_rhs.flatten() - F @ D @ beta_sample)\n",
    "\n",
    "        sum_term1 += torch.dot(z_sample, alpha_sample)\n",
    "    term1[i] = sum_term1 / trace_samples\n",
    "\n",
    "# -------------------\n",
    "# Final gradient for each hyperparameter:\n",
    "# grad_i = 0.5 * [ term1_i - term2_i ]\n",
    "grad = 0.5 * (term1 - term2)\n",
    "print(term2.real)\n",
    "    # return grad.real\n",
    "    # save the gradients for each loop\n",
    "    # if iter == 0:\n",
    "    #     grad_all = grad\n",
    "    # else:\n",
    "    #     grad_all = torch.cat([grad_all, grad], dim=0)\n",
    "    \n",
    "    # Print the gradients.\n",
    "# grad = efgp1d_gradient(x, y, sigmasq, kernel,EPSILON,trace_samples=10)\n",
    "# for i in range(grad.shape[0]):\n",
    "#     print(f\"Hyperparameter {i}: gradient approx = {grad[i].real.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import math\n",
    "from efgp1d import compute_convolution_vector_vectorized, FFTConv1d, BatchFFTConv1d\n",
    "\n",
    "\n",
    "\n",
    "sigmasq = torch.tensor(0.1, dtype=torch.float64)  # noise variance\n",
    "init_kernel\n",
    "x_new = x \n",
    "num_iters = 1\n",
    "def efgp1d_gradient(x, y, sigmasq, kernel,eps,trace_samples):\n",
    "    # x = x.to(dtype=torch.float64).flatten()   # shape: (N,)\n",
    "    y = y.to(dtype=torch.float64).flatten()     # shape: (N,)\n",
    "    x0, x1 = torch.min(x), torch.max(x)\n",
    "    # opts = {'get_var': True, 'get_log_marginal_likelihood': True}\n",
    "    L = x1 - x0\n",
    "    N = x.shape[0]\n",
    "    # eps = EPSILON\n",
    "    # eps = 1e-20\n",
    "\n",
    "    # Get Fourier frequencies and weights.\n",
    "    xis, h, mtot = get_xis(kernel, eps, L)  # Expect len(xis)=M (e.g., M=97)\n",
    "    # Compute weights: ws = sqrt(S(xis)*h)\n",
    "    ws = torch.sqrt(kernel.spectral_density(xis) * h)  # ws: (M,)   # will change to h^d \n",
    "    D = torch.diag(ws).to(dtype=torch.complex128)         # D: (M, M)\n",
    "    \n",
    "    # Form design features F (size: (N, M)).\n",
    "    #TODO : use UFFTConv1d instead of this\n",
    "    F = torch.exp(1j * 2 * math.pi * torch.outer(x, xis)).to(dtype=torch.complex128)\n",
    "    #TODO higher dim \n",
    "    # F = torch.exp(1j * 2 * torch.pi * (x@xis.t()).to(dtype=torch.complex128))\n",
    "\n",
    "    v, j_indices = compute_convolution_vector_vectorized(m=int((mtot - 1) / 2), x=x, h=h)\n",
    "    Afun = lambda beta: D @ FFTConv1d(v, D @ beta)() + sigmasq * beta\n",
    "\n",
    "\n",
    "    # A = D @ (torch.conj(F).T @ F) @ D  # A: (M, M)\n",
    "    \n",
    "    # -------------------\n",
    "    # Compute term 2: easy way\n",
    "    # rhs = D @ torch.conj(F).T @ y.to(dtype=torch.complex128)  # rhs: (M,)\n",
    "\n",
    "\n",
    "    #via NUFFT \n",
    "    xcen = (x1+x0)/2\n",
    "    tphx = 2*math.pi*h*(x - xcen)\n",
    "    # tphxtrgs = 2*math.pi*h*(x - xcen)\n",
    "\n",
    "    \n",
    "    nuffttol = EPSILON/20\n",
    "    isign = -1\n",
    "    rhs = finufft.nufft1d1(x=tphx.numpy(), c=y.to(torch.complex128).numpy(),isign= isign, eps= nuffttol, n_modes=mtot)\n",
    "    rhs = ws * rhs;       \n",
    "\n",
    "\n",
    "\n",
    "    # cg_object = ConjugateGradients(\n",
    "    #     A_apply_function=A + sigmasq * torch.eye(mtot, dtype=A.dtype),\n",
    "    #     b=rhs,\n",
    "    #     x0=torch.zeros_like(rhs),\n",
    "    #     early_stopping=opts.get('early_stopping', False)\n",
    "    # )\n",
    "    cg_object = ConjugateGradients(\n",
    "        A_apply_function=Afun,\n",
    "        b=rhs,\n",
    "        x0=torch.zeros_like(rhs),\n",
    "        early_stopping=False\n",
    "        # early_stopping=opts.get('early_stopping', False)\n",
    "    )\n",
    "    beta = cg_object.solve()  # beta: (M,)\n",
    "    alpha = 1/sigmasq * (y - F @ D @ beta)  # alpha: (N,)\n",
    "    \n",
    "    # -------------------\n",
    "    Dprime = h * kernel.spectral_grad(xis)  # shape: (M, n_params)\n",
    "    # This yields the derivative of the diagonal of D^2, since D^2 = diag(S(xis)*h).\n",
    "    \n",
    "    # --- Embed each column of Dprime as a diagonal matrix.\n",
    "    # Dprime is (M, n_params); we want each column (length M) as an (M,M) diagonal.\n",
    "    # Transpose so each row corresponds to one hyperparameter:\n",
    "    Dprime_t = Dprime.transpose(0, 1)   # shape: (n_params, M)\n",
    "    # Embed each row into a diagonal matrix -> (n_params, M, M)\n",
    "    D_diag_temp = torch.diag_embed(Dprime_t).to(dtype=torch.complex128)  # shape: (n_params, M, M)\n",
    "    \n",
    "    # -------------------\n",
    "    # Compute khat_prime for the kernel hyperparameters:\n",
    "    # For each hyperparameter i, we want:\n",
    "    #     khat_prime_i = F * diag(Dprime_i) * F^*\n",
    "    # Expand F and its conjugate-transpose to include a batch dimension.\n",
    "    # TODO : use nufft \n",
    "    N_val, M_val = F.shape  # M_val should equal M.\n",
    "    F_expand = F.unsqueeze(0).expand(D_diag_temp.shape[0], N_val, M_val)  # shape: (n_params, N, M)\n",
    "    F_adjoint = F.conj().transpose(-2, -1)  # shape: (M, N)\n",
    "    F_adjoint_expand = F_adjoint.unsqueeze(0).expand(D_diag_temp.shape[0], M_val, N_val)  # shape: (n_params, M, N)\n",
    "    # Batched multiplication:\n",
    "\n",
    "    ## FD' F^* \n",
    "    khat_prime_kernel = torch.bmm(torch.bmm(F_expand, D_diag_temp), F_adjoint_expand)  # shape: (n_params, N, N)\n",
    "    \n",
    "    # Append the noise derivative (for noise, d/dσ² (K+σ²I) = I) as an extra hyperparameter.\n",
    "    noise_derivative = torch.eye(N, dtype=khat_prime_kernel.dtype).unsqueeze(0)  # shape: (1, N, N)\n",
    "    khat_prime_kernel_full = torch.cat([khat_prime_kernel, noise_derivative], dim=0)  # shape: (n_params+1, N, N)\n",
    "    # Optionally, permute so that the hyperparameter dimension is last:\n",
    "    khat_prime = khat_prime_kernel_full.permute(1, 2, 0)  # shape: (N, N, n_params+1)\n",
    "    \n",
    "    # -------------------\n",
    "    # Compute term 2 (quadratic term) for each hyperparameter:\n",
    "    # For hyperparameter i, term2_i = α^* (dK/dθ_i) α.\n",
    "    term2 = torch.zeros(khat_prime.shape[2], dtype=torch.complex128)\n",
    "    for i in range(khat_prime.shape[2]):\n",
    "        ## alpha^* F D' F^* alpha\n",
    "        term2[i] = torch.matmul(alpha.conj().unsqueeze(0),\n",
    "                                torch.matmul(khat_prime[:, :, i], alpha.unsqueeze(1))).squeeze()\n",
    "    \n",
    "    # -------------------\n",
    "    # Compute term 1 (trace term) via Monte Carlo.\n",
    "    # trace_samples = 10\n",
    "    # try with rademachers instead..\n",
    "\n",
    "    \n",
    "    # Z = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "    #         loc=torch.zeros_like(x),\n",
    "    #         covariance_matrix=torch.eye(N, dtype=torch.float64)\n",
    "    #     ).sample([trace_samples])  # shape: (trace_samples, N)\n",
    "    # sample Z iid rademacher variables shape (trace_samples, N)\n",
    "    Z = torch.randint(0, 2, (trace_samples, N), dtype=torch.float64) * 2 - 1\n",
    "    \n",
    "    term1 = torch.zeros(khat_prime.shape[2], dtype=torch.complex128)\n",
    "    for i in range(khat_prime.shape[2]):  # for each hyperparameter derivative\n",
    "        sum_term1 = 0.0 + 0.0j\n",
    "#TODO: fix the apply function here \n",
    "        for j in range(trace_samples):\n",
    "            z_sample = Z[j, :].to(dtype=torch.complex128)  # shape: (N,)\n",
    "            temp_rhs = khat_prime[:, :, i] @ z_sample.unsqueeze(1)  # shape: (N, 1)\n",
    "            rhs_sample = D @ torch.conj(F).T @ temp_rhs  # shape: (M, 1)\n",
    "            cg_object = ConjugateGradients(\n",
    "                A_apply_function=Afun,\n",
    "                b=rhs_sample.squeeze(),  # shape: (M,)\n",
    "                x0=torch.zeros_like(rhs_sample.squeeze()),\n",
    "                early_stopping=False\n",
    "            )\n",
    "            beta_sample = cg_object.solve()  # shape: (M,)\n",
    "            # alpha_sample = 1/sigmasq * (y - F @ D @ beta_sample)  # shape: (N,)\n",
    "            alpha_sample = 1/sigmasq * (temp_rhs.flatten() - F @ D @ beta_sample)\n",
    "\n",
    "            sum_term1 += torch.dot(z_sample, alpha_sample)\n",
    "        term1[i] = sum_term1 / trace_samples\n",
    "\n",
    "    # -------------------\n",
    "    # Final gradient for each hyperparameter:\n",
    "    # grad_i = 0.5 * [ term1_i - term2_i ]\n",
    "    grad = 0.5 * (term1 - term2)\n",
    "    # print(term2.real)\n",
    "    return grad.real\n",
    "    # save the gradients for each loop\n",
    "    # if iter == 0:\n",
    "    #     grad_all = grad\n",
    "    # else:\n",
    "    #     grad_all = torch.cat([grad_all, grad], dim=0)\n",
    "    \n",
    "    # Print the gradients.\n",
    "grad = efgp1d_gradient(x, y, sigmasq, kernel,EPSILON,trace_samples=10)\n",
    "for i in range(grad.shape[0]):\n",
    "    print(f\"Hyperparameter {i}: gradient approx = {grad[i].real.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = Z.to(dtype=torch.complex128)  # cast to complex for consistency\n",
    "\n",
    "# Define a batched operator based on FFTConv1d for use in the CG solver.\n",
    "def Afun_batch(beta):\n",
    "    \"\"\"\n",
    "    Batched operator acting on beta of shape (B, M).\n",
    "    Returns: ws * FFTConv1d(v, ws * beta)() + sigmasq * beta, shape (B, M).\n",
    "    \"\"\"\n",
    "    # Multiply beta by ws elementwise (equivalent to a diagonal D multiplication)\n",
    "    D_beta = ws * beta\n",
    "    # FFTConv1d expects the second argument to have shape (B, L); ensure beta is batched.\n",
    "    conv_result = BatchFFTConv1d(v, D_beta)()  # Output shape: (B, M) if beta is (B, M)\n",
    "    return ws * conv_result + sigmasq * beta\n",
    "\n",
    "# We'll now loop over each hyperparameter derivative index;\n",
    "# for each, we form a batched right-hand side (one per trace sample), solve the linear systems in batch,\n",
    "# and compute the corresponding trace term.\n",
    "term1 = torch.zeros(khat_prime.shape[2], dtype=torch.complex128, device=khat_prime.device)\n",
    "\n",
    "for i in range(khat_prime.shape[2]):\n",
    "    # For the i-th hyperparameter derivative, get A_i = (khat_prime)_i  of shape (N, N).\n",
    "    A_i = khat_prime[:, :, i]  # (N, N)\n",
    "    # Expand A_i into a batch to multiply with each Rademacher sample.\n",
    "    A_i_batch = A_i.unsqueeze(0).expand(trace_samples, -1, -1)  # (trace_samples, N, N)\n",
    "    \n",
    "    # Reshape Z so that each sample is a column vector.\n",
    "    z_batch = Z.unsqueeze(-1)  # (trace_samples, N, 1)\n",
    "    # Compute the right-hand side for each trace sample: temp_rhs = A_i @ z.\n",
    "\n",
    "    ## khat_prime[:, :, i] @ z_batch\n",
    "    temp_rhs_batch = torch.bmm(A_i_batch, z_batch)  # (trace_samples, N, 1)\n",
    "    \n",
    "    # Next, form the right-hand side for the linear system:\n",
    "    # b_batch = ws * (F^H @ temp_rhs).\n",
    "    # Compute F^H @ temp_rhs for each sample.\n",
    "    # Note: F^H = conj(F)^T. temp_rhs_batch: (trace_samples, N, 1), so we need to reshape F^H.\n",
    "\n",
    "\n",
    "    ## solve (FDF^*)^{-1} FD' F^* zk\n",
    "    inner = torch.matmul(temp_rhs_batch.squeeze(-1), torch.conj(F))  # (trace_samples, M)\n",
    "    b_batch = ws * inner  # (trace_samples, M)\n",
    "    \n",
    "    # Solve A x = b for all trace samples using the Batch CG solver.\n",
    "    cg_solver = BatchConjugateGradients(\n",
    "        A_apply_function=Afun_batch,\n",
    "        b=b_batch,\n",
    "        x0=torch.zeros_like(b_batch),\n",
    "        tol=1e-6,\n",
    "        early_stopping=False\n",
    "    )\n",
    "    beta_batch = cg_solver.solve()  # (trace_samples, M)\n",
    "    \n",
    "    # Compute F @ (ws * beta_batch) for each trace sample.\n",
    "    D_beta_batch = ws * beta_batch  # (trace_samples, M)\n",
    "    F_expanded = F.unsqueeze(0).expand(trace_samples, -1, -1)  # (trace_samples, N, M)\n",
    "    F_beta = torch.bmm(F_expanded, D_beta_batch.unsqueeze(-1)).squeeze(-1)  # (trace_samples, N)\n",
    "    \n",
    "    # Compute the corresponding alpha for each trace sample:\n",
    "    # alpha_batch = 1/sigmasq * (temp_rhs - F @ (ws * beta_batch))\n",
    "    temp_rhs_flat = temp_rhs_batch.squeeze(-1)  # (trace_samples, N)\n",
    "    alpha_batch = 1/sigmasq * (temp_rhs_flat - F_beta)  # (trace_samples, N)\n",
    "    \n",
    "    # Now, compute the dot product z^T * alpha for each trace sample and average.\n",
    "    dots = torch.sum(Z * alpha_batch, dim=1)  # (trace_samples,)\n",
    "    term1[i] = torch.mean(dots)\n",
    "\n",
    "print(term1.real)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batched without nufft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def efgp1d_gradient_batched(x, y, sigmasq, kernel,eps,trace_samples):\n",
    "\n",
    "\n",
    "#     # Ensure x and y are float64 and flattened.\n",
    "#     x = x.to(dtype=torch.float64).flatten()   # shape: (N,)\n",
    "#     y = y.to(dtype=torch.float64).flatten()     # shape: (N,)\n",
    "#     x0, x1 = torch.min(x), torch.max(x)\n",
    "#     L = x1 - x0\n",
    "#     N = x.shape[0]\n",
    "\n",
    "#     # Get Fourier frequencies and quadrature weights.\n",
    "#     xis, h, mtot = get_xis(kernel, eps, L)  # e.g. len(xis)==M, where M=97 for example.\n",
    "\n",
    "#     # Compute weights: ws = sqrt(S(xis) * h)\n",
    "#     ws = torch.sqrt(kernel.spectral_density(xis) * h)  # shape: (M,)\n",
    "#     # We represent D as a diagonal using ws.\n",
    "#     # Convert to complex type.\n",
    "#     ws = ws.to(dtype=torch.complex128)\n",
    "\n",
    "#     # Build design matrix features F: shape (N, M).\n",
    "#     F = torch.exp(1j * 2 * math.pi * torch.outer(x, xis)).to(dtype=torch.complex128)\n",
    "\n",
    "#     # Compute convolution vector v (and indices, if needed).\n",
    "#     v, j_indices = compute_convolution_vector_vectorized(m=int((mtot - 1) / 2), x=x, h=h)\n",
    "#     v = v.to(dtype=torch.complex128)\n",
    "\n",
    "#     # Define the operator for the main linear system.\n",
    "#     # Here, we use FFTConv1d with kernel v and treat D as a diagonal multiplication by ws.\n",
    "#     Afun = lambda beta: ws * BatchFFTConv1d(v, ws * beta)() + sigmasq * beta\n",
    "\n",
    "#     # Solve the main system with your (non-batched) conjugate gradient solver.\n",
    "#     rhs = ws * (torch.conj(F).T @ y.to(dtype=torch.complex128))  # shape: (M,)\n",
    "#     cg_object = ConjugateGradients(\n",
    "#         A_apply_function=Afun,\n",
    "#         b=rhs,\n",
    "#         x0=torch.zeros_like(rhs),\n",
    "#         early_stopping=False\n",
    "#     )\n",
    "#     beta = cg_object.solve()  # beta: (M,)\n",
    "#     alpha = 1/sigmasq * (y - F @ (ws * beta))  # shape: (N,)\n",
    "\n",
    "#     ##############################################\n",
    "#     # Compute Hyperparameter Gradients\n",
    "#     ##############################################\n",
    "#     # 1. Compute the derivative of the diagonal of D².\n",
    "#     Dprime = h * kernel.spectral_grad(xis)  # shape: (M, n_params)\n",
    "#     # Embed each column as a diagonal matrix.\n",
    "#     Dprime_t = Dprime.transpose(0, 1)  # shape: (n_params, M)\n",
    "#     D_diag_temp = torch.diag_embed(Dprime_t).to(dtype=torch.complex128)  # shape: (n_params, M, M)\n",
    "\n",
    "#     # 2. Compute khat_prime for kernel hyperparameters:\n",
    "#     #    khat_prime = F @ diag(Dprime_i) @ F^H for each hyperparameter i.\n",
    "#     N_val, M_val = F.shape  # (N, M)\n",
    "#     F_expand = F.unsqueeze(0).expand(D_diag_temp.shape[0], N_val, M_val)  # (n_params, N, M)\n",
    "#     F_adjoint = torch.conj(F).transpose(-2, -1)  # (M, N)\n",
    "#     F_adjoint_expand = F_adjoint.unsqueeze(0).expand(D_diag_temp.shape[0], M_val, N_val)  # (n_params, M, N)\n",
    "#     khat_prime_kernel = torch.bmm(torch.bmm(F_expand, D_diag_temp), F_adjoint_expand)  # (n_params, N, N)\n",
    "#     # Append the noise derivative (for σ², the derivative is I)\n",
    "#     noise_derivative = torch.eye(N, dtype=khat_prime_kernel.dtype, device=khat_prime_kernel.device).unsqueeze(0)  # (1, N, N)\n",
    "#     khat_prime_kernel_full = torch.cat([khat_prime_kernel, noise_derivative], dim=0)  # (n_params+1, N, N)\n",
    "#     # Permute so that hyperparameter derivative dimension is last.\n",
    "#     khat_prime = khat_prime_kernel_full.permute(1, 2, 0)  # shape: (N, N, n_params+1)\n",
    "\n",
    "#     # 3. Compute the quadratic form term2 for each hyperparameter:\n",
    "#     term2 = torch.zeros(khat_prime.shape[2], dtype=torch.complex128, device=khat_prime.device)\n",
    "#     for i in range(khat_prime.shape[2]):\n",
    "#         term2[i] = (torch.conj(alpha).unsqueeze(0) @ (khat_prime[:, :, i] @ alpha.unsqueeze(1))).squeeze()\n",
    "\n",
    "#     ##############################################\n",
    "#     # Monte Carlo Trace Term (term1) using Batch CG solver\n",
    "#     ##############################################\n",
    "#     # Create trace_samples Rademacher vectors. (Each entry is +1 or -1.)\n",
    "#     Z = torch.randint(0, 2, (trace_samples, N), dtype=torch.float64, device=x.device) * 2 - 1  # shape: (trace_samples, N)\n",
    "#     Z = Z.to(dtype=torch.complex128)  # cast to complex for consistency\n",
    "\n",
    "#     # Define a batched operator based on FFTConv1d for use in the CG solver.\n",
    "#     def Afun_batch(beta):\n",
    "#         \"\"\"\n",
    "#         Batched operator acting on beta of shape (B, M).\n",
    "#         Returns: ws * FFTConv1d(v, ws * beta)() + sigmasq * beta, shape (B, M).\n",
    "#         \"\"\"\n",
    "#         # Multiply beta by ws elementwise (equivalent to a diagonal D multiplication)\n",
    "#         D_beta = ws * beta\n",
    "#         # FFTConv1d expects the second argument to have shape (B, L); ensure beta is batched.\n",
    "#         conv_result = BatchFFTConv1d(v, D_beta)()  # Output shape: (B, M) if beta is (B, M)\n",
    "#         return ws * conv_result + sigmasq * beta\n",
    "\n",
    "#     # We'll now loop over each hyperparameter derivative index;\n",
    "#     # for each, we form a batched right-hand side (one per trace sample), solve the linear systems in batch,\n",
    "#     # and compute the corresponding trace term.\n",
    "#     term1 = torch.zeros(khat_prime.shape[2], dtype=torch.complex128, device=khat_prime.device)\n",
    "\n",
    "#     for i in range(khat_prime.shape[2]):\n",
    "#         # For the i-th hyperparameter derivative, get A_i = (khat_prime)_i  of shape (N, N).\n",
    "#         A_i = khat_prime[:, :, i]  # (N, N)\n",
    "#         # Expand A_i into a batch to multiply with each Rademacher sample.\n",
    "#         A_i_batch = A_i.unsqueeze(0).expand(trace_samples, -1, -1)  # (trace_samples, N, N)\n",
    "        \n",
    "#         # Reshape Z so that each sample is a column vector.\n",
    "#         z_batch = Z.unsqueeze(-1)  # (trace_samples, N, 1)\n",
    "#         # Compute the right-hand side for each trace sample: temp_rhs = A_i @ z.\n",
    "#         temp_rhs_batch = torch.bmm(A_i_batch, z_batch)  # (trace_samples, N, 1)\n",
    "        \n",
    "#         # Next, form the right-hand side for the linear system:\n",
    "#         # b_batch = ws * (F^H @ temp_rhs).\n",
    "#         # Compute F^H @ temp_rhs for each sample.\n",
    "#         # Note: F^H = conj(F)^T. temp_rhs_batch: (trace_samples, N, 1), so we need to reshape F^H.\n",
    "#         inner = torch.matmul(temp_rhs_batch.squeeze(-1), torch.conj(F))  # (trace_samples, M)\n",
    "#         b_batch = ws * inner  # (trace_samples, M)\n",
    "        \n",
    "#         # Solve A x = b for all trace samples using the Batch CG solver.\n",
    "#         cg_solver = BatchConjugateGradients(\n",
    "#             A_apply_function=Afun_batch,\n",
    "#             b=b_batch,\n",
    "#             x0=torch.zeros_like(b_batch),\n",
    "#             tol=1e-6,\n",
    "#             early_stopping=False\n",
    "#         )\n",
    "#         beta_batch = cg_solver.solve()  # (trace_samples, M)\n",
    "        \n",
    "#         # Compute F @ (ws * beta_batch) for each trace sample.\n",
    "#         D_beta_batch = ws * beta_batch  # (trace_samples, M)\n",
    "#         F_expanded = F.unsqueeze(0).expand(trace_samples, -1, -1)  # (trace_samples, N, M)\n",
    "#         F_beta = torch.bmm(F_expanded, D_beta_batch.unsqueeze(-1)).squeeze(-1)  # (trace_samples, N)\n",
    "        \n",
    "#         # Compute the corresponding alpha for each trace sample:\n",
    "#         # alpha_batch = 1/sigmasq * (temp_rhs - F @ (ws * beta_batch))\n",
    "#         temp_rhs_flat = temp_rhs_batch.squeeze(-1)  # (trace_samples, N)\n",
    "#         alpha_batch = 1/sigmasq * (temp_rhs_flat - F_beta)  # (trace_samples, N)\n",
    "        \n",
    "#         # Now, compute the dot product z^T * alpha for each trace sample and average.\n",
    "#         dots = torch.sum(Z * alpha_batch, dim=1)  # (trace_samples,)\n",
    "#         term1[i] = torch.mean(dots)\n",
    "\n",
    "#     ##############################################\n",
    "#     # Final Hyperparameter Gradients\n",
    "#     ##############################################\n",
    "#     grad = 0.5 * (term1 - term2)\n",
    "#     grad = grad.real  # if only the real parts are desired\n",
    "#     # print(\"Gradient for hyperparameters:\", grad)\n",
    "\n",
    "#     return grad\n",
    "# grad = efgp1d_gradient_batched(x, y, sigmasq, kernel,EPSILON,trace_samples=10)\n",
    "# for i in range(grad.shape[0]):\n",
    "#     print(f\"Hyperparameter {i}: gradient approx = {grad[i].real.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using flatiron NUFFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def efgp1d_gradient_batched(x, y, sigmasq, kernel,eps,trace_samples,x0,x1):\n",
    "#     n_hypers = 3  # number of hyperparameters\n",
    "\n",
    "#     # Ensure x and y are float64 and flattened.\n",
    "#     # x = x.to(dtype=torch.float64).flatten()   # shape: (N,)\n",
    "#     # y = y.to(dtype=torch.float64).flatten()     # shape: (N,)\n",
    "\n",
    "#     # x0 = xmin\n",
    "#     # x1 = xmax\n",
    "#     L = x1 - x0\n",
    "#     N = x.shape[0]\n",
    "\n",
    "#     # Get Fourier frequencies and quadrature weights.\n",
    "#     xis, h, mtot = get_xis(kernel, eps, L)  # e.g. len(xis)==M, where M=97 for example.\n",
    "\n",
    "#     # Compute weights: ws = sqrt(S(xis) * h)\n",
    "#     ws = torch.sqrt(kernel.spectral_density(xis) * h)  # shape: (M,)\n",
    "#     # We represent D as a diagonal using ws.\n",
    "#     # Convert to complex type.\n",
    "#     ws = ws.to(dtype=torch.complex128)\n",
    "#     v = compute_convolution_vector_vectorized(m=int((mtot - 1) / 2), x=x, h=h)\n",
    "#     Afun = lambda beta: ws * BatchFFTConv1d(v, ws * beta)() + sigmasq * beta #O(N + MlogM)?\n",
    "\n",
    "\n",
    "\n",
    "#     #via NUFFT \n",
    "#     # xcen = (x1+x0)/2\n",
    "#     xcen = 0\n",
    "#     tphx = 2*math.pi*h*(x - xcen)\n",
    "#     # tphxtrgs = 2*math.pi*h*(x - xcen)\n",
    "\n",
    "\n",
    "#     nuffttol = 1e-15\n",
    "#     isign = -1\n",
    "\n",
    "#     # no matter what we incur a cost of O(N + MlogM) here, but would be faster to plan outside the training loop\n",
    "\n",
    "\n",
    "#     fadjbeta = lambda beta: torch.tensor(finufft.nufft1d1(x=tphx.numpy(),\n",
    "#                                                            c=beta.to(torch.complex128).numpy(),\n",
    "#                                                            isign= isign, eps= nuffttol, n_modes=mtot)) #O(N+ MlogM)?\n",
    "#         ##NUFFT version\n",
    "#     fbeta = lambda beta: torch.tensor(\n",
    "#     finufft.nufft1d2(\n",
    "#         x=tphx.numpy(),\n",
    "#         f=beta.to(torch.complex128).numpy(),\n",
    "#         isign=1,\n",
    "#         eps=nuffttol,\n",
    "#         # n_modes=mtot\n",
    "#     )\n",
    "#     )\n",
    "\n",
    "\n",
    "#     rhs = fadjbeta(y)\n",
    "#     # print(rhs.shape)\n",
    "#     rhs = ws * rhs       \n",
    "\n",
    "\n",
    "#     cg_object = ConjugateGradients(\n",
    "#         A_apply_function=Afun,\n",
    "#         b=rhs,\n",
    "#         x0=torch.zeros_like(rhs),\n",
    "#         early_stopping=False\n",
    "#         # early_stopping=opts.get('early_stopping', False)\n",
    "#     )\n",
    "#     beta = cg_object.solve()  # beta: (M,)\n",
    "#     alpha = 1/sigmasq * (y - fbeta( ws * beta))  # alpha: (N,)\n",
    "\n",
    "#     # -------------------\n",
    "#     Dprime = h * kernel.spectral_grad(xis)  # shape: (M, n_params)\n",
    "#     # This yields the derivative of the diagonal of D^2, since D^2 = diag(S(xis)*h).\n",
    "#     term2 = torch.zeros(n_hypers, dtype=torch.complex128)\n",
    "#     fadjalpha = fadjbeta(alpha)\n",
    "\n",
    "#     for i in range(3-1):\n",
    "#         ## alpha^* F D' F^* alpha\n",
    "#         term2[i] = fadjalpha.conj()@ (Dprime[:,i]*fadjalpha)\n",
    "#     # term2[i] = torch.matmul(alpha.conj().unsqueeze(0),\n",
    "#     #                         torch.matmul(khat_prime[:, :, i], alpha.unsqueeze(1))).squeeze()\n",
    "#     term2[-1] = alpha.conj() @ alpha  # noise term\n",
    "#     # -------------------\n",
    "#     # Compute term 1 (trace term) via Monte Carlo.\n",
    "#     # trace_samples = 10\n",
    "#     # try with rademachers instead..\n",
    "\n",
    "#     ##############################################\n",
    "#     # Monte Carlo Trace Term (term1) using Batch CG solver\n",
    "#     ##############################################\n",
    "#     # Create trace_samples Rademacher vectors. (Each entry is +1 or -1.)\n",
    "#     Z = torch.randint(0, 2, (trace_samples, N), dtype=torch.float64, device=x.device) * 2 - 1  # shape: (trace_samples, N)\n",
    "#     Z = Z.to(dtype=torch.complex128)  # cast to complex for consistency\n",
    "\n",
    "#     # Define a batched operator based on FFTConv1d for use in the CG solver.\n",
    "#     def Afun_batch(beta):\n",
    "#         \"\"\"\n",
    "#         Batched operator acting on beta of shape (B, M).\n",
    "#         Returns: ws * FFTConv1d(v, ws * beta)() + sigmasq * beta, shape (B, M).\n",
    "#         \"\"\"\n",
    "#         # Multiply beta by ws elementwise (equivalent to a diagonal D multiplication)\n",
    "#         D_beta = ws * beta\n",
    "#         # FFTConv1d expects the second argument to have shape (B, L); ensure beta is batched.\n",
    "#         conv_result = BatchFFTConv1d(v, D_beta)()  # Output shape: (B, M) if beta is (B, M)\n",
    "#         return ws * conv_result + sigmasq * beta\n",
    "\n",
    "#     B_list       = []\n",
    "#     temp_rhs_list = []\n",
    "#     p = 3\n",
    "#     #TODO this is dependent on the kernel.. \n",
    "#     fadjz = fadjbeta(Z)\n",
    "#     for i in range(p):\n",
    "#         if i < p-1:\n",
    "#             # term‑1 for hyper i\n",
    "#             trhs = fbeta( ( fadjz * Dprime[:, i]) )\n",
    "#         else:\n",
    "#             # noise‑term has RHS = Z itself\n",
    "#             trhs = Z                 # shape (T, N)\n",
    "#         temp_rhs_list.append(trhs)\n",
    "\n",
    "#         Bi = fadjbeta(trhs) * ws     # shape (T, M)\n",
    "#         B_list.append(Bi)\n",
    "\n",
    "#     # 2) Concatenate into one big batched RHS of shape (p*T, M)\n",
    "#     B_all = torch.cat(B_list, dim=0)         # (p*T, M)\n",
    "#     TR_all = torch.cat(temp_rhs_list, dim=0) # (p*T, N)\n",
    "\n",
    "#     # 3) One single batched CG solve\n",
    "#     cg = BatchConjugateGradients(\n",
    "#         A_apply_function=Afun_batch,\n",
    "#         b=B_all,\n",
    "#         x0=torch.zeros_like(B_all),\n",
    "#         tol=1e-6,\n",
    "#         early_stopping=False\n",
    "#     )\n",
    "#     Beta_all = cg.solve()      # shape (p*T, M)\n",
    "\n",
    "#     # 4) Recover the alpha’s in one go\n",
    "#     #    α = (temp_rhs - F β·ws) / σ²\n",
    "#     WS = ws.unsqueeze(0)               # shape (1, M)\n",
    "#     FB = fbeta(Beta_all * WS)          # (p*T, N)\n",
    "#     Alpha_all = (TR_all - FB) / sigmasq  # (p*T, N)\n",
    "\n",
    "#     # 5) Split back into p blocks of size T\n",
    "#     Alpha_blocks = Alpha_all.chunk(p, dim=0)  # list of p tensors, each (T, N)\n",
    "\n",
    "#     # 6) Compute term1[i] = mean over T samples of <Z, α_i>\n",
    "#     term1 = torch.empty(p, dtype=torch.complex128, device=x.device)\n",
    "#     for i, α_block in enumerate(Alpha_blocks):\n",
    "#         # Z is (T, N); α_block is (T, N)\n",
    "#         dots = (Z * α_block).sum(dim=1)       # (T,)\n",
    "#         term1[i] = dots.mean()\n",
    "\n",
    "#     # … then term2 as before, and grad = 0.5*(term1 - term2)\n",
    "\n",
    "\n",
    "#     # final gradients \n",
    "#     grad = 0.5 * (term1 - term2)\n",
    "#     grad = grad.real  # if only the real parts are desired\n",
    "    \n",
    "#     # print(\"Gradient for hyperparameters:\", grad)\n",
    "\n",
    "#     return grad\n",
    "# grad = efgp1d_gradient_batched(x, y, sigmasq, kernel,EPSILON,trace_samples=10,x0=x0,x1=x1)\n",
    "# for i in range(grad.shape[0]):\n",
    "#     print(f\"Hyperparameter {i}: gradient approx = {grad[i].real.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# previous gradient version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def efgp1d_gradient_batched(x, y, sigmasq, kernel,eps,trace_samples,x0,x1):\n",
    "#     n_hypers = 3  # number of hyperparameters\n",
    "\n",
    "#     # Ensure x and y are float64 and flattened.\n",
    "#     # x = x.to(dtype=torch.float64).flatten()   # shape: (N,)\n",
    "#     # y = y.to(dtype=torch.float64).flatten()     # shape: (N,)\n",
    "\n",
    "#     # x0 = xmin\n",
    "#     # x1 = xmax\n",
    "#     L = x1 - x0\n",
    "#     N = x.shape[0]\n",
    "\n",
    "#     # Get Fourier frequencies and quadrature weights.\n",
    "#     xis, h, mtot = get_xis(kernel, eps, L)  # e.g. len(xis)==M, where M=97 for example.\n",
    "\n",
    "#     # Compute weights: ws = sqrt(S(xis) * h)\n",
    "#     ws = torch.sqrt(kernel.spectral_density(xis) * h)  # shape: (M,)\n",
    "#     # We represent D as a diagonal using ws.\n",
    "#     # Convert to complex type.\n",
    "#     ws = ws.to(dtype=torch.complex128)\n",
    "#     v = compute_convolution_vector_vectorized(m=int((mtot - 1) / 2), x=x, h=h)\n",
    "#     Afun = lambda beta: ws * BatchFFTConv1d(v, ws * beta)() + sigmasq * beta #O(N + MlogM)?\n",
    "\n",
    "\n",
    "\n",
    "#     #via NUFFT \n",
    "#     # xcen = (x1+x0)/2\n",
    "#     xcen = 0\n",
    "#     tphx = 2*math.pi*h*(x - xcen)\n",
    "#     # tphxtrgs = 2*math.pi*h*(x - xcen)\n",
    "\n",
    "\n",
    "#     nuffttol = 1e-15\n",
    "#     isign = -1\n",
    "\n",
    "#     # no matter what we incur a cost of O(N + MlogM) here, but would be faster to plan outside the training loop\n",
    "#     fadjbeta = lambda beta: torch.tensor(finufft.nufft1d1(x=tphx.numpy(),\n",
    "#                                                            c=beta.to(torch.complex128).numpy(),\n",
    "#                                                            isign= isign, eps= nuffttol, n_modes=mtot)) #O(N+ MlogM)?\n",
    "#         ##NUFFT version\n",
    "#     fbeta = lambda beta: torch.tensor(\n",
    "#     finufft.nufft1d2(\n",
    "#         x=tphx.numpy(),\n",
    "#         f=beta.to(torch.complex128).numpy(),\n",
    "#         isign=1,\n",
    "#         eps=nuffttol,\n",
    "#         # n_modes=mtot\n",
    "#     )\n",
    "# )\n",
    "#     rhs = fadjbeta(y)\n",
    "#     rhs = ws * rhs       \n",
    "\n",
    "\n",
    "#     cg_object = ConjugateGradients(\n",
    "#         A_apply_function=Afun,\n",
    "#         b=rhs,\n",
    "#         x0=torch.zeros_like(rhs),\n",
    "#         early_stopping=False\n",
    "#         # early_stopping=opts.get('early_stopping', False)\n",
    "#     )\n",
    "#     beta = cg_object.solve()  # beta: (M,)\n",
    "#     alpha = 1/sigmasq * (y - fbeta( ws * beta))  # alpha: (N,)\n",
    "\n",
    "#     # -------------------\n",
    "#     Dprime = h * kernel.spectral_grad(xis)  # shape: (M, n_params)\n",
    "#     # This yields the derivative of the diagonal of D^2, since D^2 = diag(S(xis)*h).\n",
    "#     term2 = torch.zeros(n_hypers, dtype=torch.complex128)\n",
    "#     for i in range(3-1):\n",
    "#         ## alpha^* F D' F^* alpha\n",
    "#         fadjalpha = fadjbeta(alpha)\n",
    "#         term2[i] = fadjalpha.conj()@ (Dprime[:,i]*fadjalpha)\n",
    "#     # term2[i] = torch.matmul(alpha.conj().unsqueeze(0),\n",
    "#     #                         torch.matmul(khat_prime[:, :, i], alpha.unsqueeze(1))).squeeze()\n",
    "#     term2[-1] = alpha.conj() @ alpha  # noise term\n",
    "#     # -------------------\n",
    "#     # Compute term 1 (trace term) via Monte Carlo.\n",
    "#     # trace_samples = 10\n",
    "#     # try with rademachers instead..\n",
    "\n",
    "#     ##############################################\n",
    "#     # Monte Carlo Trace Term (term1) using Batch CG solver\n",
    "#     ##############################################\n",
    "#     # Create trace_samples Rademacher vectors. (Each entry is +1 or -1.)\n",
    "#     Z = torch.randint(0, 2, (trace_samples, N), dtype=torch.float64, device=x.device) * 2 - 1  # shape: (trace_samples, N)\n",
    "#     Z = Z.to(dtype=torch.complex128)  # cast to complex for consistency\n",
    "\n",
    "#     # Define a batched operator based on FFTConv1d for use in the CG solver.\n",
    "#     def Afun_batch(beta):\n",
    "#         \"\"\"\n",
    "#         Batched operator acting on beta of shape (B, M).\n",
    "#         Returns: ws * FFTConv1d(v, ws * beta)() + sigmasq * beta, shape (B, M).\n",
    "#         \"\"\"\n",
    "#         # Multiply beta by ws elementwise (equivalent to a diagonal D multiplication)\n",
    "#         D_beta = ws * beta\n",
    "#         # FFTConv1d expects the second argument to have shape (B, L); ensure beta is batched.\n",
    "#         conv_result = BatchFFTConv1d(v, D_beta)()  # Output shape: (B, M) if beta is (B, M)\n",
    "#         return ws * conv_result + sigmasq * beta\n",
    "\n",
    "#     term1 = torch.zeros(n_hypers, dtype=torch.complex128)\n",
    "\n",
    "#     # will have to change for different kernels.. \n",
    "#     for i in range(n_hypers):\n",
    "#         if i<n_hypers-1:\n",
    "#             temp_rhs = (fbeta((fadjbeta(Z) * Dprime[:,i])))\n",
    "#         else:\n",
    "#             temp_rhs = Z\n",
    "#         b_batch = (fadjbeta(temp_rhs) * ws)\n",
    "#         cg_solver = BatchConjugateGradients(\n",
    "#             A_apply_function=Afun_batch,\n",
    "#             b=b_batch,\n",
    "#             x0=torch.zeros_like(b_batch),\n",
    "#             tol=1e-6,\n",
    "#             early_stopping=False\n",
    "#         )\n",
    "#         beta_batch = cg_solver.solve()  # (trace_samples, M)\n",
    "#         alpha_batch = 1/sigmasq * (temp_rhs - (fbeta(beta_batch*ws)))\n",
    "#         dots = torch.sum(Z * alpha_batch, dim=1) \n",
    "#         term1[i] = torch.mean(dots)\n",
    "\n",
    "#     # final gradients \n",
    "#     grad = 0.5 * (term1 - term2)\n",
    "#     grad = grad.real  # if only the real parts are desired\n",
    "    \n",
    "#     # print(\"Gradient for hyperparameters:\", grad)\n",
    "\n",
    "#     return grad\n",
    "# grad = efgp1d_gradient_batched(x, y, sigmasq, kernel,EPSILON,trace_samples=10,x0=x0,x1=x1)\n",
    "# for i in range(grad.shape[0]):\n",
    "#     print(f\"Hyperparameter {i}: gradient approx = {grad[i].real.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import math\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # --- Assumed Inputs (Define these *before* this block) ---\n",
    "# # x: Training inputs (N, d) tensor, device=device, dtype=rdtype\n",
    "# # y: Training outputs (N,) tensor, device=device, dtype=rdtype\n",
    "# # x_new: Test inputs (B, d) tensor, device=device, dtype=rdtype\n",
    "# # xis: Frequency points (M, d) tensor, device=device, dtype=rdtype\n",
    "# # ws: Spectral weights sqrt(density*h^d) (M,) tensor, device=device, dtype=cdtype\n",
    "# # sigmasq: Noise variance (scalar float)\n",
    "# # variance_direct: Pre-calculated exact variance (B,) tensor, device=device, dtype=rdtype\n",
    "# # BatchConjugateGradients: Class or function for batched CG solves\n",
    "# # device: torch.device\n",
    "# # rdtype: torch.float64\n",
    "# # cdtype: torch.complex128\n",
    "# # -----------------------------------------------------------\n",
    "\n",
    "# # --- Self-Contained Hutchinson Block ---\n",
    "\n",
    "# # --- Setup ---\n",
    "# print(\"Starting Hutchinson Estimation Block...\")\n",
    "# N, d = x.shape\n",
    "# B = x_new.shape[0]\n",
    "# M = xis.shape[0]\n",
    "# if d != 1:\n",
    "#     print(f\"Warning: Hutchinson variance estimation is implemented assuming d=1 for final summation.\")\n",
    "#     # Or raise NotImplementedError(\"Hutchinson diagonal sum variance estimation requires d=1.\")\n",
    "\n",
    "# # Device/Type Setup (Redundant if defined globally, but safe)\n",
    "# device = x.device\n",
    "# rdtype = torch.float64\n",
    "# cdtype = torch.complex128\n",
    "\n",
    "# # Ensure inputs are correct type/device (Redundant if done globally)\n",
    "# x = x.to(device, rdtype)\n",
    "# y = y.to(device, rdtype)\n",
    "# x_new = x_new.to(device, rdtype)\n",
    "# xis = xis.to(device, rdtype)\n",
    "# ws = ws.to(device, cdtype)\n",
    "# sigmasq_scalar = float(sigmasq) # Use scalar float for division/addition alpha\n",
    "\n",
    "# # Recompute F_train (needed for A)\n",
    "# print(\"Computing F_train...\")\n",
    "# F_train = torch.exp(2 * math.pi * 1j * torch.matmul(x, xis.T)).to(cdtype)\n",
    "\n",
    "# # Define D (Diagonal matrix from weights)\n",
    "# print(\"Defining D...\")\n",
    "# D = torch.diag(ws) # Assuming ws components are positive sqrt\n",
    "\n",
    "# # # Define h (Frequency spacing - Crucial for final summation step)\n",
    "# # h = torch.tensor(0.0, device=device, dtype=rdtype) # Initialize\n",
    "# # if M > 1 and d == 1:\n",
    "# #    # Calculate spacing from the first dimension assuming uniform grid\n",
    "# #    h = (xis[1, 0] - xis[0, 0]).abs()\n",
    "# #    print(f\"Calculated frequency spacing h = {h.item()}\")\n",
    "# # elif M > 1 and d > 1:\n",
    "# #    # Assume spacing is the same in all dimensions for simplicity? Or take first dim?\n",
    "# #    h = (xis[1, 0] - xis[0, 0]).abs() # Using first dim as convention\n",
    "# #    print(f\"Warning: Using h from first dimension for d={d}. h = {h.item()}\")\n",
    "# # else: # M <= 1\n",
    "# #    h = torch.tensor(1.0, device=device, dtype=rdtype) # Placeholder if M=1\n",
    "# #    print(f\"Warning: M={M}. Using placeholder h=1.0\")\n",
    "# # if h <= 1e-12:\n",
    "# #     print(f\"Warning: Calculated h ({h.item()}) is very small or zero. Check xis.\")\n",
    "# #     h = torch.tensor(1.0, device=device, dtype=rdtype) # Reset to avoid division issues\n",
    "\n",
    "# # Create identity matrix for M dimensions\n",
    "# I_M = torch.eye(M, device=device, dtype=cdtype) # Use cdtype for complex arithmetic\n",
    "\n",
    "# # 1) Re-build A = (D F^H F D)/σ^2 + I_M\n",
    "# print(\"Building matrix A...\")\n",
    "# F_conj_T = F_train.conj().T\n",
    "# # Ensure matrix multiplications are correct device/type\n",
    "# A = (D @ F_conj_T @ F_train @ D) / sigmasq_scalar + I_M\n",
    "# print(f\"Matrix A shape: {A.shape}, dtype: {A.dtype}\")\n",
    "\n",
    "# # --- Hutchinson-type Estimation Block ---\n",
    "\n",
    "# # 2) draw J Rademacher probes with length M\n",
    "# J = 5000 # Number of probes\n",
    "# print(f\"Generating {J} Rademacher probes...\")\n",
    "# # Sample ±1 i.i.d. (Rademacher), then cast to complex\n",
    "# etas = (torch.randint(0, 2, (J, M), device=device, dtype=rdtype) * 2 - 1).to(dtype=cdtype)  # Shape (J, M)\n",
    "\n",
    "# # 3) solve A u = D η via batched‐CG, then set γ = D u\n",
    "# print(\"Calculating RHS for CG...\")\n",
    "# rhs = (D @ etas.T).T # Shape (J, M)\n",
    "\n",
    "# # Define the batched matrix-vector product for A\n",
    "# def A_apply_batched(x):\n",
    "#     # x is (J, M). A is (M, M).\n",
    "#     return x @ A # (J, M) @ (M, M) -> (J, M)\n",
    "\n",
    "# # Use a very tight tolerance\n",
    "# cg_tol = 1e-6 # TIGHT tolerance\n",
    "# max_cg_iter = M * 5 # Increase iterations further if needed\n",
    "\n",
    "# print(f\"Running Batch CG (tol={cg_tol}, max_iter={max_cg_iter})...\")\n",
    "# cg = BatchConjugateGradients(\n",
    "#     A_apply_batched, rhs, \n",
    "#     tol=cg_tol,\n",
    "#     max_iter=max_cg_iter,\n",
    "#     x0=torch.zeros_like(rhs), # Use complex zeros\n",
    "#     early_stopping=True\n",
    "# )\n",
    "# us = cg.solve() # shape (J, M) solves A u = D eta\n",
    "\n",
    "# print(\"Calculating gammas...\")\n",
    "# gammas = (D @ us.T).T # shape (J, M) approximates C^{-1} @ etas\n",
    "\n",
    "# # 4) form Hutchinson estimates of the diagonal sums Sum_i Cinv[i, i+k]\n",
    "# print(\"Estimating diagonal sums...\")\n",
    "# offsets = list(range(-(M-1), M))\n",
    "# num_offsets = len(offsets)\n",
    "# est_sums = torch.zeros(num_offsets, device=device, dtype=cdtype)\n",
    "\n",
    "# # Precompute conjugate probes\n",
    "# etas_conj = etas.conj()\n",
    "\n",
    "# # --- Vectorized calculation over probes J ---\n",
    "# for i, k in enumerate(offsets):\n",
    "#     est_sum_val = torch.tensor(0.0 + 0.0j, device=device, dtype=cdtype)\n",
    "#     if k == 0:\n",
    "#         est_sum_val = torch.sum(etas_conj * gammas, dim=1).mean()\n",
    "#     elif k > 0:\n",
    "#         overlap = M - k\n",
    "#         if overlap > 0:\n",
    "#             est_sum_val = torch.sum(etas_conj[:, :overlap] * gammas[:, k:], dim=1).mean()\n",
    "#     else:  # k < 0\n",
    "#         k_abs = abs(k)\n",
    "#         overlap = M - k_abs\n",
    "#         if overlap > 0:\n",
    "#             est_sum_val = torch.sum(etas_conj[:, k_abs:] * gammas[:, :overlap], dim=1).mean()\n",
    "#     est_sums[i] = est_sum_val\n",
    "# print(\"Diagonal sum estimation complete.\")\n",
    "\n",
    "# # 5) Diagnostics (Optional - Compare est_sums to true_sums)\n",
    "# print(\"Performing diagnostics on diagonal sums...\")\n",
    "# try:\n",
    "#     with torch.no_grad(): # Avoid tracking gradients for inversion/diagonals\n",
    "#         D_inv = torch.diag(1.0 / torch.diag(D))\n",
    "#         C0 = D_inv @ A @ D_inv\n",
    "#         Cinv = torch.linalg.inv(C0)\n",
    "#         true_sums = torch.zeros(len(offsets), device=device, dtype=cdtype)\n",
    "#         for i_diag, k_diag in enumerate(offsets):\n",
    "#             true_sums[i_diag] = Cinv.diagonal(offset=k_diag).sum().to(cdtype)\n",
    "\n",
    "#         err_diag_sums = est_sums - true_sums\n",
    "#         rel_errors = err_diag_sums / true_sums\n",
    "#         print(f\"Max Abs Error (est_sums vs true_sums): {err_diag_sums.abs().max().item():.2e}\")\n",
    "#         print(f\"RMSE (est_sums vs true_sums):        {torch.sqrt((err_diag_sums.abs()**2).mean()).item():.2e}\")\n",
    "\n",
    "#         plt.figure(figsize=(15, 5))\n",
    "#         plt.subplot(1, 3, 1)\n",
    "#         plt.plot(offsets, true_sums.real.cpu().numpy(), 'bo-', ms=4, label=\"True Sums (Real)\")\n",
    "#         plt.plot(offsets, est_sums.real.cpu().numpy(), 'rx--', ms=4, label=\"Est Sums (Real)\")\n",
    "#         plt.xlabel(\"Diagonal offset k\")\n",
    "#         plt.ylabel(\"Sum Value (Real Part)\")\n",
    "#         plt.title(\"Comparison of Diagonal Sums\")\n",
    "#         plt.legend()\n",
    "#         plt.grid(True)\n",
    "\n",
    "#         plt.subplot(1, 3, 2)\n",
    "#         plt.plot(offsets, err_diag_sums.abs().cpu().numpy(), '.-')\n",
    "#         plt.xlabel(\"Diagonal offset k\")\n",
    "#         plt.ylabel(\"|Error|\")\n",
    "#         plt.title(\"Magnitude of Error\")\n",
    "#         plt.yscale('log')\n",
    "#         plt.grid(True)\n",
    "\n",
    "#         plt.subplot(1, 3, 3)\n",
    "#         plt.plot(offsets, rel_errors.abs().cpu().numpy(), '.-')\n",
    "#         plt.xlabel(\"Diagonal offset k\")\n",
    "#         plt.ylabel(\"Relative Error\")\n",
    "#         plt.title(\"Relative Error (Log Scale)\")\n",
    "#         plt.yscale('log')\n",
    "#         plt.grid(True)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "# except Exception as e:\n",
    "#     print(f\"Could not compute true_sums or diagnostics: {e}\")\n",
    "#     true_sums = None\n",
    "\n",
    "# # 6) Build the difference‐grid and frequency weights (assuming d=1)\n",
    "# print(\"Building final summation weights...\")\n",
    "# xi_diff = torch.tensor(offsets, device=device, dtype=rdtype) * h  # (num_offsets,)\n",
    "\n",
    "# x_new_1d = x_new.squeeze()\n",
    "# if x_new_1d.dim() != 1:\n",
    "#      raise ValueError(f\"x_new could not be squeezed to 1D. Original shape: {x_new.shape}\")\n",
    "\n",
    "# exponent_arg = -2j * math.pi * (x_new_1d.unsqueeze(1) * xi_diff.unsqueeze(0))\n",
    "# expo_diff = torch.exp(exponent_arg).to(dtype=cdtype)\n",
    "\n",
    "# # 7) Form the final variance estimate s_est = Re(expo_diff @ est_sums)\n",
    "# print(\"Calculating final variance estimate s_est...\")\n",
    "# s_est = (expo_diff @ est_sums).real\n",
    "# s_est = torch.clamp_min(s_est, 0.0)\n",
    "\n",
    "# # 8) Final Comparison Plot\n",
    "# all_vals = torch.cat((s_est.cpu(), variance_direct.cpu())).numpy()\n",
    "# min_val = min(0, all_vals.min()) * 1.1\n",
    "# max_val = max(0, all_vals.max()) * 1.1\n",
    "# lims = [min_val, max_val]\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(lims, lims, 'r--', alpha=0.7, label='y=x')\n",
    "# plt.scatter(s_est.cpu().numpy(), variance_direct.cpu().numpy(), label=\"Hutchinson (s_est)\", s=20)\n",
    "# plt.xlabel(\"s_est (Hutchinson Estimate)\")\n",
    "# plt.ylabel(\"variance_direct\")\n",
    "# plt.title(\"Variance Comparison (Cleaned Hutchinson)\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.xlim(lims)\n",
    "# plt.ylim(lims)\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(x_new_1d.cpu().numpy(), s_est.cpu().numpy(), 'b.-', label='s_est (Hutchinson)')\n",
    "# plt.plot(x_new_1d.cpu().numpy(), variance_direct.cpu().numpy(), 'r.-', label='variance_direct')\n",
    "# plt.xlabel(\"x_new\")\n",
    "# plt.ylabel(\"Variance\")\n",
    "# plt.title(\"Variance Estimates vs. Position\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Hutchinson Estimation Block Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import math\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # --- Assumed Inputs (Define these *before* this block) ---\n",
    "# # x: Training inputs (N, d) tensor, device=device, dtype=rdtype\n",
    "# # y: Training outputs (N,) tensor, device=device, dtype=rdtype\n",
    "# # x_new: Test inputs (B, d) tensor, device=device, dtype=rdtype\n",
    "# # xis: Frequency points (M, d) tensor, device=device, dtype=rdtype\n",
    "# # ws: Spectral weights sqrt(density*h^d) (M,) tensor, device=device, dtype=cdtype\n",
    "# # sigmasq: Noise variance (scalar float)\n",
    "# # variance_direct: Pre-calculated exact variance (B,) tensor, device=device, dtype=rdtype\n",
    "# # BatchConjugateGradients: Class or function for batched CG solves\n",
    "# # device: torch.device\n",
    "# # rdtype: torch.float64\n",
    "# # cdtype: torch.complex128\n",
    "# # -----------------------------------------------------------\n",
    "\n",
    "# # --- Self-Contained Hutchinson Block ---\n",
    "\n",
    "# # --- Setup ---\n",
    "# print(\"Starting Hutchinson Estimation Block...\")\n",
    "# N, d = x.shape\n",
    "# B = x_new.shape[0]\n",
    "# M = xis.shape[0]\n",
    "# if d != 1:\n",
    "#     print(f\"Warning: Hutchinson variance estimation is implemented assuming d=1 for final summation.\")\n",
    "#     # Or raise NotImplementedError(\"Hutchinson diagonal sum variance estimation requires d=1.\")\n",
    "\n",
    "# # Device/Type Setup (Redundant if defined globally, but safe)\n",
    "# device = x.device\n",
    "# rdtype = torch.float64\n",
    "# cdtype = torch.complex128\n",
    "\n",
    "# # Ensure inputs are correct type/device (Redundant if done globally)\n",
    "# x = x.to(device, rdtype)\n",
    "# y = y.to(device, rdtype)\n",
    "# x_new = x_new.to(device, rdtype)\n",
    "# xis = xis.to(device, rdtype)\n",
    "# ws = ws.to(device, cdtype)\n",
    "# sigmasq_scalar = float(sigmasq) # Use scalar float for division/addition alpha\n",
    "\n",
    "# # Recompute F_train (needed for A)\n",
    "# print(\"Computing F_train...\")\n",
    "# F_train = torch.exp(2 * math.pi * 1j * torch.matmul(x, xis.T)).to(cdtype)\n",
    "\n",
    "# # Define D (Diagonal matrix from weights)\n",
    "# print(\"Defining D...\")\n",
    "# D = torch.diag(ws) # Assuming ws components are positive sqrt\n",
    "\n",
    "# # Define h (Frequency spacing - Crucial for final summation step)\n",
    "# # h = torch.tensor(0.0, device=device, dtype=rdtype) # Initialize\n",
    "# # if M > 1 and d == 1:\n",
    "# #    # Calculate spacing from the first dimension assuming uniform grid\n",
    "# #    h = (xis[1, 0] - xis[0, 0]).abs()\n",
    "# #    print(f\"Calculated frequency spacing h = {h.item()}\")\n",
    "# # elif M > 1 and d > 1:\n",
    "# #    # Assume spacing is the same in all dimensions for simplicity? Or take first dim?\n",
    "# #    h = (xis[1, 0] - xis[0, 0]).abs() # Using first dim as convention\n",
    "# #    print(f\"Warning: Using h from first dimension for d={d}. h = {h.item()}\")\n",
    "# # else: # M <= 1\n",
    "# #    h = torch.tensor(1.0, device=device, dtype=rdtype) # Placeholder if M=1\n",
    "# #    print(f\"Warning: M={M}. Using placeholder h=1.0\")\n",
    "# # if h <= 1e-12:\n",
    "# #     print(f\"Warning: Calculated h ({h.item()}) is very small or zero. Check xis.\")\n",
    "# #     h = torch.tensor(1.0, device=device, dtype=rdtype) # Reset to avoid division issues\n",
    "\n",
    "# # Create identity matrix for M dimensions\n",
    "# I_M = torch.eye(M, device=device, dtype=cdtype) # Use cdtype for complex arithmetic\n",
    "\n",
    "# # 1) Re-build A = (D F^H F D)/σ^2 + I_M\n",
    "# print(\"Building matrix A...\")\n",
    "# F_conj_T = F_train.conj().T\n",
    "# # Ensure matrix multiplications are correct device/type\n",
    "# A = (D @ F_conj_T @ F_train @ D) / sigmasq_scalar + I_M\n",
    "# print(f\"Matrix A shape: {A.shape}, dtype: {A.dtype}\")\n",
    "\n",
    "# # --- Hutchinson-type Estimation Block ---\n",
    "\n",
    "# # 2) draw J Rademacher probes with length M\n",
    "# J = 10000 # Number of probes\n",
    "# print(f\"Generating {J} Rademacher probes...\")\n",
    "# # Sample ±1 i.i.d. (Rademacher), then cast to complex\n",
    "# etas = (torch.randint(0, 2, (J, M), device=device, dtype=rdtype) * 2 - 1).to(dtype=cdtype)  # Shape (J, M)\n",
    "\n",
    "# # 3) solve A u = D η via batched‐CG, then set γ = D u\n",
    "# print(\"Calculating RHS for CG...\")\n",
    "# rhs = (D @ etas.T).T # Shape (J, M)\n",
    "\n",
    "# # Define the batched matrix-vector product for A\n",
    "# def A_apply_batched(x):\n",
    "#     # x is (J, M). A is (M, M).\n",
    "#     return x @ A # (J, M) @ (M, M) -> (J, M)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"Running Batch CG (tol={cg_tol}, max_iter={max_cg_iter})...\")\n",
    "# cg = BatchConjugateGradients(\n",
    "#     A_apply_batched, rhs, \n",
    "#     tol=cg_tol,\n",
    "#     max_iter=max_cg_iter,\n",
    "#     x0=torch.zeros_like(rhs), # Use complex zeros\n",
    "#     early_stopping=True\n",
    "# )\n",
    "# us = cg.solve() # shape (J, M) solves A u = D eta\n",
    "\n",
    "# print(\"Calculating gammas...\")\n",
    "# gammas = (D @ us.T).T # shape (J, M) approximates C^{-1} @ etas\n",
    "\n",
    "# # 4) form Hutchinson estimates of the diagonal sums Sum_i Cinv[i, i+k]\n",
    "# print(\"Estimating diagonal sums...\")\n",
    "# offsets = list(range(-(M-1), M))\n",
    "# num_offsets = len(offsets)\n",
    "# est_sums = torch.zeros(num_offsets, device=device, dtype=cdtype)\n",
    "\n",
    "# # Precompute conjugate probes\n",
    "# etas_conj = etas.conj()\n",
    "\n",
    "# # --- Vectorized calculation over probes J ---\n",
    "# # 4) form Hutchinson estimates of the diagonal sums via one FFT-based convolution\n",
    "# print(\"Estimating diagonal sums via FFT-based convolution...\")\n",
    "\n",
    "# # zero-pad both gammas and etas to length L >= 2*M-1 so that circular conv = linear conv\n",
    "# L = 1 << ((2*M - 1).bit_length())           # next power of two ≥ 2*M-1\n",
    "# pad = L - M\n",
    "\n",
    "# # (J, M) → (J, L)\n",
    "# gammas_pad = torch.cat([gammas, torch.zeros(J, pad, dtype=cdtype, device=device)], dim=1)\n",
    "# etas_pad   = torch.cat([etas_conj, torch.zeros(J, pad, dtype=cdtype, device=device)], dim=1)\n",
    "\n",
    "# # FFTs (O(L log L) each)\n",
    "# G = torch.fft.fft(gammas_pad, n=L)         # (J, L//2+1)\n",
    "# E = torch.fft.fft(etas_pad,   n=L)         # (J, L//2+1)\n",
    "\n",
    "# # pointwise product → iFFT to get full linear cross-correlation of length L\n",
    "# R = torch.fft.ifft(G * torch.conj(E), n=L)\n",
    "\n",
    "\n",
    "# # 1) positive-and-zero lags:  j = 0,1,...,M-1\n",
    "# pos = R[:, :M]                        # shape (J, M)\n",
    "\n",
    "# # 2) negative lags: j = -(M-1),..., -1  →  indices L-(M-1) ... L-1\n",
    "# neg = R[:, L-(M-1) : L]               # shape (J, M-1)\n",
    "\n",
    "# # 3) concatenate so that rags[:, 0] = c_{-(M-1)}, ... , rags[:, M-1] = c_0, ... rags[:, 2M-2] = c_{M-1}\n",
    "# rags = torch.cat([neg, pos], dim=1)   # shape (J, 2*M-1)\n",
    "\n",
    "# # 4) average over the J Monte–Carlo samples\n",
    "# est_sums = rags.mean(dim=0)           # (2*M-1,)\n",
    "# # making symmetric\n",
    "\n",
    "# ## double check this \n",
    "# # est_sums = (est_sums + est_sums.flip(0)) * 0.5\n",
    "\n",
    "# print(\"Diagonal sum estimation complete.\")\n",
    "\n",
    "\n",
    "# # 5) Diagnostics (Optional - Compare est_sums to true_sums)\n",
    "# print(\"Performing diagnostics on diagonal sums...\")\n",
    "# try:\n",
    "#     with torch.no_grad(): # Avoid tracking gradients for inversion/diagonals\n",
    "#         D_inv = torch.diag(1.0 / torch.diag(D))\n",
    "#         C0 = D_inv @ A @ D_inv\n",
    "#         Cinv = torch.linalg.inv(C0)\n",
    "#         true_sums = torch.zeros(len(offsets), device=device, dtype=cdtype)\n",
    "#         for i_diag, k_diag in enumerate(offsets):\n",
    "#             true_sums[i_diag] = Cinv.diagonal(offset=k_diag).sum().to(cdtype)\n",
    "\n",
    "#         err_diag_sums = est_sums - true_sums\n",
    "#         rel_errors = err_diag_sums / true_sums\n",
    "#         print(f\"Max Abs Error (est_sums vs true_sums): {err_diag_sums.abs().max().item():.2e}\")\n",
    "#         print(f\"RMSE (est_sums vs true_sums):        {torch.sqrt((err_diag_sums.abs()**2).mean()).item():.2e}\")\n",
    "\n",
    "#         plt.figure(figsize=(15, 5))\n",
    "#         plt.subplot(1, 3, 1)\n",
    "#         plt.plot(offsets, true_sums.real.cpu().numpy(), 'bo-', ms=4, label=\"True Sums (Real)\")\n",
    "#         plt.plot(offsets, est_sums.real.cpu().numpy(), 'rx--', ms=4, label=\"Est Sums (Real)\")\n",
    "#         plt.xlabel(\"Diagonal offset k\")\n",
    "#         plt.ylabel(\"Sum Value (Real Part)\")\n",
    "#         plt.title(\"Comparison of Diagonal Sums\")\n",
    "#         plt.legend()\n",
    "#         plt.grid(True)\n",
    "\n",
    "#         plt.subplot(1, 3, 2)\n",
    "#         plt.plot(offsets, err_diag_sums.abs().cpu().numpy(), '.-')\n",
    "#         plt.xlabel(\"Diagonal offset k\")\n",
    "#         plt.ylabel(\"|Error|\")\n",
    "#         plt.title(\"Magnitude of Error\")\n",
    "#         plt.yscale('log')\n",
    "#         plt.grid(True)\n",
    "\n",
    "#         plt.subplot(1, 3, 3)\n",
    "#         plt.plot(offsets, rel_errors.abs().cpu().numpy(), '.-')\n",
    "#         plt.xlabel(\"Diagonal offset k\")\n",
    "#         plt.ylabel(\"Relative Error\")\n",
    "#         plt.title(\"Relative Error (Log Scale)\")\n",
    "#         plt.yscale('log')\n",
    "#         plt.grid(True)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "# except Exception as e:\n",
    "#     print(f\"Could not compute true_sums or diagnostics: {e}\")\n",
    "#     true_sums = None\n",
    "\n",
    "# # 6) Build the difference‐grid and frequency weights (assuming d=1)\n",
    "# print(\"Building final summation weights...\")\n",
    "# xi_diff = torch.tensor(offsets, device=device, dtype=rdtype) * h  # (num_offsets,)\n",
    "# est_sums = est_sums.contiguous()          # complex tensor, shape (N,)\n",
    "# assert est_sums.shape[0] == xi_diff.shape[0], \"length mismatch!\"\n",
    "\n",
    "# N = est_sums.shape[0]       # total modes (25)\n",
    "# K = (N - 1) // 2            # highest ±k    (12)\n",
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # 1.  direct reference result (for sanity check)\n",
    "# # ------------------------------------------------------------\n",
    "# # x_new_1d = x_new.squeeze()               # shape (B,)\n",
    "# # expo = torch.exp(\n",
    "# #         -2j * math.pi * (x_new_1d[:,None] * xi_diff[None,:])\n",
    "# #       ).to(dtype=cdtype)\n",
    "# # s_direct = (expo @ est_sums).real        # shape (B,)\n",
    "\n",
    "# # ------------------------------------------------------------\n",
    "# # 2.  NUFFT path – put coeffs in FFT order, call FINUFFT\n",
    "# # ------------------------------------------------------------\n",
    "# fk_fft = torch.roll(est_sums, -K)        # CMCL → FFT order (ifftshift)\n",
    "\n",
    "# phi = (-2 * math.pi * h * (x_new_1d - xcen)).unsqueeze(0)  # shape (1,B)\n",
    "\n",
    "# s_est_complex = pff.finufft_type2(\n",
    "#         phi, fk_fft, eps=nufft_eps, isign=1, modeord=True  # FFT order\n",
    "# )\n",
    "# s_nufft = s_est_complex.real\n",
    "# # print(\"max |difference|:\", (s_nufft - s_direct).abs().max())\n",
    "\n",
    "\n",
    "# # 7) Form the final variance estimate s_est = Re(expo_diff @ est_sums)\n",
    "# print(\"Calculating final variance estimate s_est...\")\n",
    "# # x_new_1d = x_new.squeeze()\n",
    "# # if x_new_1d.dim() != 1:\n",
    "# #      raise ValueError(f\"x_new could not be squeezed to 1D. Original shape: {x_new.shape}\")\n",
    "\n",
    "# # exponent_arg = -2j * math.pi * (x_new_1d.unsqueeze(1) * xi_diff.unsqueeze(0))\n",
    "# # expo_diff = torch.exp(exponent_arg).to(dtype=cdtype)\n",
    "\n",
    "# # # 7) Form the final variance estimate s_est = Re(expo_diff @ est_sums)\n",
    "# # print(\"Calculating final variance estimate s_est...\")\n",
    "# # s_est = (expo_diff @ est_sums).real\n",
    "# # s_est = torch.clamp_min(s_est, 0.0)\n",
    "# s_est = s_nufft\n",
    "# # 8) Final Comparison Plot\n",
    "# all_vals = torch.cat((s_est.cpu(), variance_direct.cpu())).numpy()\n",
    "# min_val = min(0, all_vals.min()) * 1.1\n",
    "# max_val = max(0, all_vals.max()) * 1.1\n",
    "# lims = [min_val, max_val]\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(lims, lims, 'r--', alpha=0.7, label='y=x')\n",
    "# plt.scatter(s_est.cpu().numpy(), variance_direct.cpu().numpy(), label=\"Hutchinson (s_est)\", s=20)\n",
    "# plt.xlabel(\"s_est (Hutchinson Estimate)\")\n",
    "# plt.ylabel(\"variance_direct\")\n",
    "# plt.title(\"Variance Comparison (Cleaned Hutchinson)\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.xlim(lims)\n",
    "# plt.ylim(lims)\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(x_new_1d.cpu().numpy(), s_est.cpu().numpy(), 'b.-', label='s_est (Hutchinson)')\n",
    "# plt.plot(x_new_1d.cpu().numpy(), variance_direct.cpu().numpy(), 'r.-', label='variance_direct')\n",
    "# plt.xlabel(\"x_new\")\n",
    "# plt.ylabel(\"Variance\")\n",
    "# plt.title(\"Variance Estimates vs. Position\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Hutchinson Estimation Block Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sum ests in 1d old misaligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 1d \n",
    "\n",
    "\n",
    "# # def diag_sums(A_apply_batched,J,M,max_cg_iter,cg_tol):\n",
    "# #     ## Takes an operator A_apply_batched and returns an estimate of the diagonal sums of the inverse of A\n",
    "# #     ## Using Hutchinson's method with offsets\n",
    "# #     ## Solve Au = eta via batched CG, then set gamma = u\n",
    "# #     ## Then use convolution of gamma with eta to get the diagonal sums of the inverse of A\n",
    "# #     etas = (torch.randint(0, 2, (J, M), device=device, dtype=rdtype) * 2 - 1).to(dtype=cdtype)  # Shape (J, M)\n",
    "\n",
    "# #     # 3) solve A u = D eta via batched‐CG, then set gamma= D u\n",
    "# #     print(\"Calculating RHS for CG...\")\n",
    "# #     rhs = (ws * etas) # Shape (J, M)\n",
    "\n",
    "# #     print(f\"Running Batch CG (tol={cg_tol}, max_iter={max_cg_iter})...\")\n",
    "# #     cg = BatchConjugateGradients(\n",
    "# #         A_apply_batched, rhs, \n",
    "# #         tol=cg_tol,\n",
    "# #         max_iter=max_cg_iter,\n",
    "# #         x0=torch.zeros_like(rhs), \n",
    "# #         early_stopping=True\n",
    "# #     )\n",
    "# #     us = cg.solve() # shape (J, M) solves A u = D eta\n",
    "\n",
    "# #     print(\"Calculating gammas...\")\n",
    "# #     gammas = (ws * us) # shape (J, M) approximates C^{-1} @ etas\n",
    "\n",
    "# #     # 4) form Hutchinson estimates of the diagonal sums Sum_i Cinv[i, i+k]\n",
    "# #     print(\"Estimating diagonal sums...\")\n",
    "# #     offsets = list(range(-(M-1), M))\n",
    "# #     num_offsets = len(offsets)\n",
    "# #     est_sums = torch.zeros(num_offsets, device=device, dtype=cdtype)\n",
    "\n",
    "\n",
    "# #     # --- Vectorized calculation over probes J ---\n",
    "# #     # 4) form Hutchinson estimates of the diagonal sums via one FFT-based convolution\n",
    "# #     print(\"Estimating diagonal sums via FFT-based convolution...\")\n",
    "\n",
    "# #     # zero-pad both gammas and etas to length L >= 2*M-1 so that circular conv = linear conv\n",
    "# #     L = 1 << ((2*M - 1).bit_length())           # next power of two ≥ 2*M-1\n",
    "# #     pad = L - M\n",
    "\n",
    "# #     # (J, M) → (J, L)\n",
    "# #     gammas_pad = torch.cat([gammas, torch.zeros(J, pad, dtype=cdtype, device=device)], dim=1)\n",
    "# #     etas_pad   = torch.cat([etas, torch.zeros(J, pad, dtype=cdtype, device=device)], dim=1)\n",
    "\n",
    "# #     # FFTs (O(L log L) each)\n",
    "# #     G = torch.fft.fft(gammas_pad, n=L)         # (J, L//2+1)\n",
    "# #     E = torch.fft.fft(etas_pad,   n=L)         # (J, L//2+1)\n",
    "\n",
    "# #     # pointwise product → iFFT to get full linear cross-correlation of length L\n",
    "# #     R = torch.fft.ifft(G * torch.conj(E), n=L)\n",
    "\n",
    "\n",
    "# #     # 1) positive-and-zero lags:  j = 0,1,...,M-1\n",
    "# #     pos = R[:, :M]                        # shape (J, M)\n",
    "\n",
    "# #     # 2) negative lags: j = -(M-1),..., -1  →  indices L-(M-1) ... L-1\n",
    "# #     neg = R[:, L-(M-1) : L]               # shape (J, M-1)\n",
    "\n",
    "# #     # 3) concatenate so that rags[:, 0] = c_{-(M-1)}, ... , rags[:, M-1] = c_0, ... rags[:, 2M-2] = c_{M-1}\n",
    "# #     rags = torch.cat([neg, pos], dim=1)   # shape (J, 2*M-1)\n",
    "\n",
    "# #     # 4) average over the J Monte–Carlo samples\n",
    "# #     est_sums = rags.mean(dim=0)           # (2*M-1,)\n",
    "# #     return est_sums\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # est_sums = diag_sums(A_var_apply,J,M,max_cg_iter,cg_tol)\n",
    "\n",
    "# if d==1:\n",
    "#     x_new_1d = x_new.squeeze()               # shape (B,)\n",
    "\n",
    "#     ## Plotting check\n",
    "#     D_inv = torch.diag(1.0 / torch.diag(D))\n",
    "#     A = (D @ F_conj_T @ F_train @ D) / sigmasq + I_M\n",
    "\n",
    "#     C0 = D_inv @ A @ D_inv\n",
    "#     Cinv = torch.linalg.inv(C0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     true_sums = torch.zeros(len(offsets), device=device, dtype=cdtype)\n",
    "#     for i_diag, k_diag in enumerate(offsets):\n",
    "#         true_sums[i_diag] = Cinv.diagonal(offset=k_diag).sum().to(cdtype)\n",
    "\n",
    "#     err_diag_sums = est_sums - true_sums\n",
    "#     rel_errors = err_diag_sums / true_sums\n",
    "#     print(f\"Max Abs Error (est_sums vs true_sums): {err_diag_sums.abs().max().item():.2e}\")\n",
    "#     print(f\"RMSE (est_sums vs true_sums):        {torch.sqrt((err_diag_sums.abs()**2).mean()).item():.2e}\")\n",
    "\n",
    "#     plt.figure(figsize=(15, 5))\n",
    "#     plt.subplot(1, 3, 1)\n",
    "#     plt.plot(offsets, true_sums.real.cpu().numpy(), 'bo-', ms=4, label=\"True Sums (Real)\")\n",
    "#     plt.plot(offsets, est_sums.real.cpu().numpy(), 'rx--', ms=4, label=\"Est Sums (Real)\")\n",
    "#     plt.xlabel(\"Diagonal offset k\")\n",
    "#     plt.ylabel(\"Sum Value (Real Part)\")\n",
    "#     plt.title(\"Comparison of Diagonal Sums\")\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "\n",
    "#     plt.subplot(1, 3, 2)\n",
    "#     plt.plot(offsets, err_diag_sums.abs().cpu().numpy(), '.-')\n",
    "#     plt.xlabel(\"Diagonal offset k\")\n",
    "#     plt.ylabel(\"|Error|\")\n",
    "#     plt.title(\"Magnitude of Error\")\n",
    "#     plt.yscale('log')\n",
    "#     plt.grid(True)\n",
    "\n",
    "#     plt.subplot(1, 3, 3)\n",
    "#     plt.plot(offsets, rel_errors.abs().cpu().numpy(), '.-')\n",
    "#     plt.xlabel(\"Diagonal offset k\")\n",
    "#     plt.ylabel(\"Relative Error\")\n",
    "#     plt.title(\"Relative Error (Log Scale)\")\n",
    "#     plt.yscale('log')\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## TODO Fix for 3D\n",
    "# def nufft_var_est(est_sums,h,xcen,nufft_eps):\n",
    "\n",
    "#     ## Takes an estimate of the diagonal sums of the inverse of A and returns an estimate of the variance\n",
    "#     ## Using the NUFFT to compute \\sum_{k\\in [-M,M]} exp(2 \\pi i k x) \\hat{C}_{k}\n",
    "#     # xi_diff = torch.tensor(offsets, device=device, dtype=rdtype) * h  # (num_offsets,)\n",
    "#     # est_sums = est_sums.contiguous()          # complex tensor, shape (N,)\n",
    "#     # assert est_sums.shape[0] == xi_diff.shape[0], \"length mismatch!\"\n",
    "\n",
    "#     N = est_sums.shape[0]       # total modes (25)\n",
    "#     K = (N - 1) // 2            # highest ±k    (12)\n",
    "\n",
    "#     # ------------------------------------------------------------\n",
    "#     # 1.  direct reference result (for sanity check)\n",
    "#     # ------------------------------------------------------------\n",
    "#     # x_new_1d = x_new.squeeze()               # shape (B,)\n",
    "#     # expo = torch.exp(\n",
    "#     #         -2j * math.pi * (x_new_1d[:,None] * xi_diff[None,:])\n",
    "#     #       ).to(dtype=cdtype)\n",
    "#     # s_direct = (expo @ est_sums).real        # shape (B,)\n",
    "\n",
    "#     # ------------------------------------------------------------\n",
    "#     # 2.  NUFFT path – put coeffs in FFT order, call FINUFFT\n",
    "#     # ------------------------------------------------------------\n",
    "#     # TODO understand the ordering of the FFT, for now just know it matches with the reference result\n",
    "#     # TODO this might change in 3d, need to check\n",
    "#     # fk_fft should be size \n",
    "#     fk_fft = torch.roll(est_sums, -K)        # CMCL → FFT order (ifftshift)\n",
    "\n",
    "#     phi = (2 * math.pi * (h*(x_new - xcen)))  # shape (1,B)\n",
    "\n",
    "#     s_est_complex = pff.finufft_type2(\n",
    "#             phi.T, fk_fft, eps=nufft_eps, isign=1, modeord=True  # FFT order\n",
    "#     )\n",
    "#     s_nufft = s_est_complex.real\n",
    "#     return s_nufft\n",
    "# import torch, math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
