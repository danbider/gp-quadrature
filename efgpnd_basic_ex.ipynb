{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# from kernels.squared_exponential import SquaredExponential\n",
    "# from kernels.matern import Matern\n",
    "from torch.optim import Adam\n",
    "\n",
    "# import sys\n",
    "import math\n",
    "# sys.path.append('/Users/colecitrenbaum/Documents/GPs/gp-quadrature/Tests and Sanity Checks/')\n",
    "from efgpnd import EFGPND\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\", message=\".*disabling cuda.*\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating some synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Parameters ---\n",
    "n = 10_000  # Number of points\n",
    "d = 2  # Dimensionality of the input space\n",
    "true_length_scale =0.15\n",
    "true_variance = 1\n",
    "true_noise_variance = 0.2\n",
    "dtype = torch.float32  # Use float64 as in the original example\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Generate Input Points ---\n",
    "# Generate random points in d-dimensional space from -1 to 1\n",
    "x = torch.rand(n, d, dtype=dtype, device=device) * 2 - 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test points (grid of points for visualization if d <= 3)\n",
    "if d >= 2:\n",
    "    # Create a grid of points for testing\n",
    "    grid_points_per_dim = 20\n",
    "    grid_points = [torch.linspace(x.min()-0.1, 0.1+x.max(), grid_points_per_dim, dtype=dtype, device=device) for _ in range(d)]\n",
    "    mesh_grid = torch.meshgrid(*grid_points, indexing='ij')\n",
    "    x_new = torch.stack([grid.flatten() for grid in mesh_grid], dim=1)\n",
    "elif d==1:\n",
    "    grid_points_per_dim = 3000\n",
    "    grid_points = [torch.linspace(x.min()-0.1, 0.1+x.max(), grid_points_per_dim, dtype=dtype, device=device) for _ in range(d)]\n",
    "    mesh_grid = torch.meshgrid(*grid_points, indexing='ij')\n",
    "    x_new = torch.stack([grid.flatten() for grid in mesh_grid], dim=1)\n",
    "else:\n",
    "    # For higher dimensions, just use random test points\n",
    "    x_new = torch.rand(1000, d, dtype=dtype, device=device) * 2.4 - 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vanilla_gp_sampling import sample_gp_fast, sample_gp_matern\n",
    "\n",
    "# # For squared exponential kernel\n",
    "samples_se = sample_gp_fast(\n",
    "    x,\n",
    "    length_scale=true_length_scale,\n",
    "    variance=true_variance,\n",
    "    noise_variance=true_noise_variance\n",
    ")\n",
    "# # For Matern kernel\n",
    "# samples_m32 = sample_gp_matern(\n",
    "#     x,\n",
    "#     nu=1.5,  # 3/2 Matern\n",
    "#     length_scale=true_length_scale,\n",
    "#     variance=true_variance,\n",
    "#     noise_variance=true_noise_variance\n",
    "# )\n",
    "y = samples_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using EFGPND "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= 2 \n",
    "EPSILON = 1e-4 # bound on kernel error \n",
    "cg_tol = EPSILON "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter learning\n",
    "    Note I hooked optimizer.step() to sync_parameters() so that the kernel is updated after each step, so that compute gradients is always called with the latest kernel hyperparameters.\n",
    "    Also, compute_gradients by default puts the grads in model._gp_params.hyper.rawgrad so that optimizer can use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ε=0.0001 | J=5] iter   0  ℓ=0.2976  σ_f²=0.819  σ_n²=0.1042\n",
      "[ε=0.0001 | J=5] iter  10  ℓ=0.1452  σ_f²=1.676  σ_n²=0.2244\n",
      "[ε=0.0001 | J=5] iter  20  ℓ=0.12  σ_f²=1.817  σ_n²=0.2554\n",
      "[ε=0.0001 | J=5] iter  30  ℓ=0.1266  σ_f²=1.387  σ_n²=0.205\n",
      "[ε=0.0001 | J=5] iter  40  ℓ=0.1434  σ_f²=0.9796  σ_n²=0.1831\n",
      "Final hyperparams: ℓ=0.1434, σ_f²=0.9796, σ_n²=0.1831\n"
     ]
    }
   ],
   "source": [
    "max_iters = 50\n",
    "J = 5\n",
    "## hyper learning with Adam\n",
    "model = EFGPND(x, y, kernel=\"SquaredExponential\", eps=EPSILON)\n",
    "# params = next(model.parameters())\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.1)\n",
    "for it in range(max_iters):\n",
    "    optimizer.zero_grad()\n",
    "     # saves grads in model._gp_params so that we can step \n",
    "    model.compute_gradients(\n",
    "                trace_samples=J,\n",
    "            )\n",
    "\n",
    "    optimizer.step() \n",
    "    \n",
    "\n",
    "\n",
    "    if it % 10 == 0:\n",
    "        lengthscale = model.kernel.get_hyper('lengthscale')\n",
    "        variance = model.kernel.get_hyper('variance')\n",
    "        sigmasq = model._gp_params.sig2.item()\n",
    "        # Get current values for printing\n",
    "        print(f\"[ε={EPSILON} | J={J}] iter {it:>3}  \"\n",
    "            f\"ℓ={lengthscale:.4g}  \"\n",
    "            f\"σ_f²={variance:.4g}  σ_n²={sigmasq:.4g}\")\n",
    "\n",
    "print(f'Final hyperparams: ℓ={lengthscale:.4g}, σ_f²={variance:.4g}, σ_n²={sigmasq:.4g}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting posterior mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"fit\" is confusing here\n",
    "- Context variables instead of all the opts \n",
    "- with .... settings = exact... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time without variance: 0.0412 seconds; x_new.shape = torch.Size([400, 2])\n"
     ]
    }
   ],
   "source": [
    "# Time different variance estimation methods\n",
    "import time\n",
    "\n",
    "# No variance\n",
    "start_time = time.time()\n",
    "mean_no_var, _= model.predict(x_new, return_variance=False)\n",
    "no_var_time = time.time() - start_time\n",
    "print(f\"Time without variance: {no_var_time:.4f} seconds; x_new.shape = {x_new.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior variance -- Stochastic Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time with stochastic variance, x_new.shape = torch.Size([400, 2]), 100 probes: 0.7475 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "hutchinson_probes = 100\n",
    "mean, stoch_var = model.predict(x_new, return_variance=True, variance_method=\"stochastic\", hutchinson_probes=hutchinson_probes)\n",
    "stoch_var_time = time.time() - start_time\n",
    "print(f\"Time with stochastic variance, x_new.shape = {x_new.shape}, {hutchinson_probes} probes: {stoch_var_time:.4f} seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior variance -- regular method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time with regular variance, x_new.shape = torch.Size([400, 2]): 2.5758 seconds\n"
     ]
    }
   ],
   "source": [
    "# Regular variance\n",
    "start_time = time.time()\n",
    "mean, var = model.predict(x_new, return_variance=True, variance_method=\"regular\")\n",
    "reg_var_time = time.time() - start_time\n",
    "print(f\"Time with regular variance, x_new.shape = {x_new.shape}: {reg_var_time:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
